{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83e9bb1-19af-44ad-b36b-a01903bf9282",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108ed5a9-812b-4b5b-9953-a5376331350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/eda/data\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/eda/data\n",
    "\n",
    "from osgeo import gdal, gdal_array, osr, ogr\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio import mask\n",
    "import pyproj\n",
    "from affine import Affine\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from geopandas import GeoDataFrame\n",
    "import geopandas as gpd\n",
    "from rasterio.features import shapes\n",
    "import xarray\n",
    "import matplotlib.pyplot as plt\n",
    "import rtree\n",
    "import shapely\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f011a2ed-a5f7-41f2-a844-13b27f129cea",
   "metadata": {},
   "source": [
    "### Load census block and census tract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae65fa4-87d5-4293-b512-14bd82fd819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#census blocks\n",
    "cb_df = gpd.read_file('./shapefiles/nycb2020_22b/nycb2020.shp')\n",
    "cb_df.columns = cb_df.columns.str.lower()\n",
    "\n",
    "#census tracts\n",
    "ct_df = gpd.read_file('./shapefiles/nyct2020_22b/nyct2020.shp')\n",
    "ct_df.columns = ct_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32d5d53-18be-4434-a379-7a163b5e6102",
   "metadata": {},
   "source": [
    "### Create feature generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c16d310-48ae-4b12-bb57-ce405e9f5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_lc_features(df, filepath, num_classes = 9, prefix = 'land_cvr_', default_val = 0, rebase = True):\n",
    "    \n",
    "    lc_data = rasterio.open(filepath)\n",
    "    feat_names = [prefix+str(i) for i in range(num_classes)] \n",
    "    if rebase:\n",
    "        rb_feat_names = [prefix + str(i) + '_rb' for i in range(1,num_classes)]\n",
    "    for feat in (feat_names + rb_feat_names):\n",
    "        df[feat] = default_val\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        filt_raster, _ = mask.mask(lc_data, [df['geometry'][i]], crop = True)\n",
    "        lc_proportion = np.histogram(filt_raster, bins = [i for i in range(num_classes + 1)])[0]/(filt_raster.shape[1]*filt_raster.shape[2])\n",
    "        for j in range(len(lc_proportion)):\n",
    "            var_name = prefix + str(j)\n",
    "            df.loc[i, var_name] = round(lc_proportion[j],6)\n",
    "            if j > 0:\n",
    "                new_var_name = var_name + '_rb'\n",
    "                df.loc[i, new_var_name] = round(df.loc[i, var_name]/(1 - df.loc[i, prefix+'0']),6)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629e5010-54e6-4ed6-8ad2-3cfbf8d71359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_elev_features(df, filepath, prefix = 'elev_', ct_level = False, default_val = 0):\n",
    "    \n",
    "    if ct_level:\n",
    "        suffix = '_ct'\n",
    "    else:\n",
    "        suffix = ''\n",
    "    \n",
    "    elev_data = rasterio.open(filepath)\n",
    "    feat_names = [prefix + i + suffix for i in ['mean','min','max','q1','q3']] \n",
    "    for feat in feat_names:\n",
    "        df[feat] = default_val\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        filt_raster, _ = mask.mask(elev_data, [df['geometry'][i]], crop = True)\n",
    "        df.loc[i, prefix + 'mean' + suffix] = round(filt_raster.mean(),1)\n",
    "        df.loc[i, prefix + 'min' + suffix], df.loc[i, prefix + 'q1' + suffix], df.loc[i, prefix + 'q3' + suffix], df.loc[i, prefix + 'max' + suffix] = np.percentile(filt_raster, [0,25,75,100])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "485cdf06-21b1-4c94-89b0-4a327cb7b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_drain_features(df, filepath):\n",
    "    \n",
    "    drain_data = gpd.read_file(filepath)\n",
    "    drain_data.columns = drain_data.columns.str.lower()\n",
    "\n",
    "    drain_data = drain_data.sjoin(df, how = 'inner', predicate = 'within')[['unitid','bctcb2020']]                                  \n",
    "    df = df.merge(drain_data.groupby('bctcb2020')['unitid'].nunique(), how = 'left', on = 'bctcb2020').rename(columns = {'unitid':'catch_basin_count'})\n",
    "    df['catch_basin_density'] = df['catch_basin_count']/df['shape_area']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2968827-d4cf-48c2-8974-29d60f49ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_subway_features(df, filepath):\n",
    "    \n",
    "    sub_data = gpd.read_file(filepath)\n",
    "    sub_data.columns = sub_data.columns.str.lower()\n",
    "\n",
    "    sub_data = sub_data.sjoin(df, how = 'inner', predicate = 'within')[['objectid','bctcb2020']]                                  \n",
    "    df = df.merge(sub_data.groupby('bctcb2020')['objectid'].nunique(), how = 'left', on = 'bctcb2020').rename(columns = {'objectid':'sub_entr_count'})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c2d3c5c-5694-488b-891c-6ffdf2ec7a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ret_wall_features(df, filepath):\n",
    "    \n",
    "    rw_data = gpd.read_file(filepath)\n",
    "    rw_data.columns = rw_data.columns.str.lower()\n",
    "    \n",
    "    rw_data = df.overlay(rw_data, how = 'intersection', keep_geom_type = False)[['bctcb2020','shape_leng_2','geometry']]\n",
    "    \n",
    "    #explode to split any multipart geometries\n",
    "    rw_data = rw_data.explode(ignore_index = True)\n",
    "    \n",
    "    length = []\n",
    "    avg_rw_elev = []\n",
    "    cb_list = []\n",
    "    for cb in rw_data.bctcb2020.unique():\n",
    "        cb_list.append(cb)\n",
    "        elev_list = []\n",
    "        subset = rw_data[rw_data.bctcb2020 == cb]\n",
    "        length.append(subset['shape_leng_2'].sum())\n",
    "        for i in range(0,len(subset)):\n",
    "            for j in list(subset.iloc[i].geometry.coords):\n",
    "                 elev_list.append(j[2])\n",
    "        avg_rw_elev.append(np.mean(elev_list))\n",
    "    \n",
    "    rw_agg = pd.DataFrame(zip(cb_list, length, avg_rw_elev),columns  = ['bctcb2020','rw_length','rw_avg_elev'])\n",
    "    df = df.merge(rw_agg, how = 'left', on = 'bctcb2020')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91bb316e-52d8-43d0-bcee-aad1c3817a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_hydro_features(df, filepath, hydro_dict):\n",
    "    \n",
    "    h_data = gpd.read_file(filepath)\n",
    "    h_data.columns = h_data.columns.str.lower()\n",
    "    \n",
    "    h_data = df.overlay(h_data, how = 'intersection', keep_geom_type = False)\n",
    "    \n",
    "    for key in hydro_dict.keys():\n",
    "        df[hydro_dict[key]] = np.where(df.bctcb2020.isin(h_data[h_data.feat_code == key].bctcb2020),1,0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d708345-6b04-4936-97db-2b01f87b6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_path = './raster_data/NYC_2017_LiDAR_LandCover.img'\n",
    "elev_path = './elevation/DEM_LiDAR_1ft_2010_Improved_NYC_int.tif'\n",
    "dr_path = './DEPCatchbasins/DEPCATCHBASINS.shp'\n",
    "se_path = './doitt_subway_entrances/DOITT_SUBWAY_ENTRANCE_04JAN2017.shp'\n",
    "rw_path = './retaining_wall/RETAININGWALL.shp'\n",
    "h_path = './hydro/HYDROGRAPHY.shp'\n",
    "\n",
    "hydro_dict = {2600:'lake_res_ind',\n",
    "              2610:'pond_ind',\n",
    "              2620:'river_ind',\n",
    "              2630:'stream_ind',\n",
    "              2640:'wl_marsh_ind',\n",
    "              2650:'beach_shore_ind',\n",
    "              2660:'bay_ocean_ind'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32703496-6d97-4947-9b5b-75ba4aa3b246",
   "metadata": {},
   "source": [
    "### Borough-Level Dataset Pipeline (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a16cc078-8b55-4ea7-8a23-6db3cbeccc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_boro_dataset(cb_df, ct_df, name, name_abv):\n",
    "    start_ = time.time()\n",
    "    df = gen_lc_features(cb_df[cb_df.boroname == name].reset_index(drop = True), lc_path)\n",
    "    print(f'Land cover features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "    df = gen_elev_features(df, elev_path)\n",
    "    print(f'CB elevation features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "    df_c = gen_elev_features(ct_df[ct_df.boroname == name].reset_index(drop = True), elev_path, ct_level = True)\n",
    "    print(f'CT elevation features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "    df = df.merge(df_c[['ct2020','ntaname','elev_mean_ct','elev_min_ct','elev_max_ct','elev_q1_ct','elev_q3_ct']], on = 'ct2020')\n",
    "    df = gen_drain_features(df, dr_path)\n",
    "    print(f'Catch basin features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "    df = gen_subway_features(df, se_path)\n",
    "    print(f'Subway features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "    df = gen_ret_wall_features(df, rw_path)\n",
    "    print(f'Retaining wall features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "    df = gen_hydro_features(df, h_path, hydro_dict)\n",
    "    print(f'Hydrography features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "    df.to_csv(f'{name_abv}_data.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01599a4f-3454-4861-bb36-d3a4e7d43e47",
   "metadata": {},
   "source": [
    "### Generate full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eac5c036-111b-44ab-9056-eb6d527feb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land cover features complete: 3.1 total time elapsed\n",
      "CB elevation features complete: 5.9 total time elapsed\n",
      "CT elevation features complete: 8.4 total time elapsed\n",
      "Catch basin features complete: 8.9 total time elapsed\n",
      "Subway features complete: 8.9 total time elapsed\n",
      "Retaining wall features complete: 9.0 total time elapsed\n",
      "Hydrography features complete: 9.0 total time elapsed\n"
     ]
    }
   ],
   "source": [
    "mht = gen_boro_dataset(cb_df, ct_df, 'Manhattan', 'mht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f996849-165f-4786-bdd7-3bb0a62716d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./mht_data.csv to s3://w210-flood-risk/modeling_data/mht_data.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp mht_data.csv s3://w210-flood-risk/modeling_data/mht_data.csv --acl public-read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a49c879-6fd3-4359-b13b-ecaa7df9aa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land cover features complete: 7.8 total time elapsed\n",
      "CB elevation features complete: 13.7 total time elapsed\n",
      "CT elevation features complete: 19.2 total time elapsed\n",
      "Catch basin features complete: 19.7 total time elapsed\n",
      "Subway features complete: 19.8 total time elapsed\n",
      "Retaining wall features complete: 19.9 total time elapsed\n",
      "Hydrography features complete: 19.9 total time elapsed\n"
     ]
    }
   ],
   "source": [
    "bk = gen_boro_dataset(cb_df, ct_df, 'Brooklyn', 'bk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93613971-4097-4307-b2f8-e5a86020d025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./bk_data.csv to s3://w210-flood-risk/modeling_data/bk_data.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp bk_data.csv s3://w210-flood-risk/modeling_data/bk_data.csv --acl public-read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c4eba90-0544-4eb7-b307-fe01cb878147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land cover features complete: 12.9 total time elapsed\n",
      "CT elevation features complete: 67.4 total time elapsed\n",
      "Catch basin features complete: 67.9 total time elapsed\n",
      "Subway features complete: 68.0 total time elapsed\n",
      "Retaining wall features complete: 68.1 total time elapsed\n",
      "Hydrography features complete: 68.2 total time elapsed\n"
     ]
    }
   ],
   "source": [
    "qns = gen_boro_dataset(cb_df, ct_df, 'Queens', 'qns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08504ee2-95dd-485e-9e9f-1c9cf75de385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./qns_data.csv to s3://w210-flood-risk/modeling_data/qns_data.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp qns_data.csv s3://w210-flood-risk/modeling_data/qns_data.csv --acl public-read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e12cfff-4713-42ad-9093-b12e87c8d6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land cover features complete: 5.4 total time elapsed\n",
      "CB elevation features complete: 8.5 total time elapsed\n",
      "CT elevation features complete: 11.1 total time elapsed\n",
      "Catch basin features complete: 11.6 total time elapsed\n",
      "Subway features complete: 11.6 total time elapsed\n",
      "Retaining wall features complete: 11.7 total time elapsed\n",
      "Hydrography features complete: 11.8 total time elapsed\n"
     ]
    }
   ],
   "source": [
    "bx = gen_boro_dataset(cb_df, ct_df, 'Bronx', 'bx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6df033-3307-4613-b837-43bb950fc39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./bx_data.csv to s3://w210-flood-risk/modeling_data/bx_data.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp bx_data.csv s3://w210-flood-risk/modeling_data/bx_data.csv --acl public-read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e0941-4727-4072-beac-fb2c2c53fafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land cover features complete: 7.4 total time elapsed\n",
      "CB elevation features complete: 11.8 total time elapsed\n",
      "CT elevation features complete: 15.4 total time elapsed\n",
      "Catch basin features complete: 15.9 total time elapsed\n",
      "Subway features complete: 15.9 total time elapsed\n",
      "Retaining wall features complete: 15.9 total time elapsed\n",
      "Hydrography features complete: 16.0 total time elapsed\n"
     ]
    }
   ],
   "source": [
    "si = gen_boro_dataset(cb_df, ct_df, 'Staten Island', 'si')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3dda7d-bb35-490a-8b2a-670a0bced363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./si_data.csv to s3://w210-flood-risk/modeling_data/si_data.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp si_data.csv s3://w210-flood-risk/modeling_data/si_data.csv --acl public-read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7cf6b4-8cb3-438f-a647-0e3ab83d2aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# start_ = time.time()\n",
    "# df = gen_lc_features(cb_df, lc_path)\n",
    "# print(f'Land cover features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "# df = gen_elev_features(df, elev_path)\n",
    "# print(f'CB elevation features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "# df_c = gen_elev_features(ct_df, elev_path, ct_level = True)\n",
    "# print(f'CT elevation features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "# df = df.merge(df_c[['ct2020','ntaname','avg_elev_ct','min_elev_ct','max_elev_ct','q1_elev_ct','q3_elev_ct']], on = 'ct2020')\n",
    "# df = gen_drain_features(df, dr_path)\n",
    "# print(f'Catch basin features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "# df = gen_subway_features(df, se_path)\n",
    "# print(f'Subway features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "# df = gen_ret_wall_features(df, rw_path)\n",
    "# print(f'Retaining wall features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "# df = gen_hydro_features(df, h_path)\n",
    "# print(f'Hydrography features complete: {round((time.time()-start_)/60,1)} total time elapsed')\n",
    "\n",
    "# df.to_csv('full_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
